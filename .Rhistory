UK1980_td <- tidy(UK1980_dfm)
UK1980_term_change <- UK1980_tf_idf %>%
extract(document, "year", "(\\d+)", convert = TRUE) %>%
complete(year, term, fill = list(count = 0)) %>%
group_by(year) %>%
mutate(year_total = sum(count))
UK1980_term_change %>%
filter(term %in% c("immigration", "immigrant", "immigrants", "migration", "refugees")) %>%
ggplot(aes(year, count / year_total)) +
geom_point() +
geom_smooth() +
facet_wrap(~ term, scales = "free_y") +
scale_y_continuous(labels = scales::percent_format()) +
ylab("% frequency of word in party manifesto")
# see rough code
UK1980_lda <- LDA(UK1980_dfm, k = 6)
#control = list(seed = 1234)
W <- UK1980_lda@gamma
H <- UK1980_lda@beta
topic_words_top <- tidy(UK1980_lda, matrix="beta")
topic_words_top
topic_words_top <- tidy(UK1980_lda, matrix="beta") %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
topic_words_top %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
# I think that if you don't separate out the manifestos from one another you end up treating everything the same, which is no good.
View(UK1980_tidied_corpus_ed)
View(UK1980_tidied_corpus_ed)
for (i in 1:29){
name = UK1980_tidied_corpus_ed$id[i]
sentences = unlist(strsplit(UK1980_tidied_corpus_ed$text[i],split = "\n"))
ids = rep(UK1980_tidied_corpus_ed$id[i], sapply(strsplit(UK1980_tidied_corpus_ed$text[i], split = "\n"), length))
new_ids = paste(ids, sequence(sapply(strsplit(UK1980_tidied_corpus_ed$text[i], split = "\n"), length)), sep = "_")
db_list[[name]] = data.frame(id = new_ids, text = sentences)
rownames(db_list[[name]]) = NULL
}
db_list <- list()
for (i in 1:29){
name = UK1980_tidied_corpus_ed$id[i]
sentences = unlist(strsplit(UK1980_tidied_corpus_ed$text[i],split = "\n"))
ids = rep(UK1980_tidied_corpus_ed$id[i], sapply(strsplit(UK1980_tidied_corpus_ed$text[i], split = "\n"), length))
new_ids = paste(ids, sequence(sapply(strsplit(UK1980_tidied_corpus_ed$text[i], split = "\n"), length)), sep = "_")
db_list[[name]] = data.frame(id = new_ids, text = sentences)
rownames(db_list[[name]]) = NULL
}
View(db_list)
library(tm)
library(SnowballC)
preprocess_text <- function(text) {
text <- tolower(text)  # Convert to lowercase
text <- gsub("[[:punct:]]", "", text)  # Remove punctuation
text <- gsub("[[:digit:]]", "", text)  # Remove numbers
text <- gsub("[ \t\r\n]+", " ", text)  # Remove extra whitespaces
text <- trimws(text)  # Remove leading and trailing whitespaces
text <- removeWords(text, stopwords("spanish"))  # Remove stopwords
text <- wordStem(text, language = "spanish")  # Stemming
}
namedb <- names(db_list)
for (i in 1:6){
name = namedb[i]
db_list[[name]][2] = sapply(db_list[[name]][2], preprocess_text)
}
View(UK1980_tidied_corpus_ed)
View(db_list)
library(quanteda)
dfmat_list<-list()
for (i in 1:6){
name = namedb[i]
dfmat_list[[name]] = unlist(db_list[[name]][2]) %>%
tokens() %>%
dfm() #%>%
#dfm_trim(min_termfreq = 5)
}
View(db_list)
library(topicmodels)
lda_list <- list()
SEED = set.seed(1500)
#this takes like 3 minutes
for (i in 1:29){
name = namedb[i]
lda_list[[name]] = LDA(dfmat_list[[name]], 10, control = list(alpha=5),seed=SEED)
}
db_list <- list()
for (i in 1:29){
name = UK1980_tidied_corpus_ed$id[i]
sentences = unlist(strsplit(UK1980_tidied_corpus_ed$text[i],split = "\n"))
ids = rep(UK1980_tidied_corpus_ed$id[i], sapply(strsplit(UK1980_tidied_corpus_ed$text[i], split = "\n"), length))
new_ids = paste(ids, sequence(sapply(strsplit(UK1980_tidied_corpus_ed$text[i], split = "\n"), length)), sep = "_")
db_list[[name]] = data.frame(id = new_ids, text = sentences)
rownames(db_list[[name]]) = NULL
}
library(tm)
library(SnowballC)
preprocess_text <- function(text) {
text <- tolower(text)  # Convert to lowercase
text <- gsub("[[:punct:]]", "", text)  # Remove punctuation
text <- gsub("[[:digit:]]", "", text)  # Remove numbers
text <- gsub("[ \t\r\n]+", " ", text)  # Remove extra whitespaces
text <- trimws(text)  # Remove leading and trailing whitespaces
text <- removeWords(text, stopwords("spanish"))  # Remove stopwords
text <- wordStem(text, language = "spanish")  # Stemming
return(text)  # Add this line
}
namedb <- names(db_list)
for (i in 1:29) {  # Change to 29
name = namedb[i]
db_list[[name]][2] <- sapply(db_list[[name]][2], function(text) if (!is.null(text)) preprocess_text(text))
}
library(quanteda)
dfmat_list<-list()
for (i in 1:29){
name = namedb[i]
dfmat_list[[name]] = unlist(db_list[[name]][2]) %>%
tokens() %>%
dfm() #%>%
#dfm_trim(min_termfreq = 5)
}
library(topicmodels)
lda_list <- list()
SEED = set.seed(1500)
for (i in 1:29) {  # Change to 29
name = namedb[i]
if (!is.empty.dfmat(dfmat_list[[name]])) {  # Check if dfmat is not empty
lda_list[[name]] = LDA(dfmat_list[[name]], 10, control = list(alpha=5), seed = SEED)
}
}
library(topicmodels)
lda_list <- list()
SEED <- set.seed(1500)
for (i in 1:29) {  # Change to 29
name <- namedb[i]
if (nfeature(dfmat_list[[name]]) > 0) {  # Check if dfmat is not empty
lda_list[[name]] <- LDA(dfmat_list[[name]], 10, control = list(alpha = 5), seed = SEED)
}
}
library(topicmodels)
lda_list <- list()
SEED = set.seed(1500)
for (i in 1:29) {  # Change to 29
name <- namedb[i]
if (ndoc(dfmat_list[[name]]) > 0) {  # Check if dfmat is not empty
lda_list[[name]] <- LDA(dfmat_list[[name]], 10, control = list(alpha = 5), seed = SEED)
}
}
library(topicmodels)
lda_list <- list()
SEED = set.seed(1500)
for (i in 1:29) {  # Change to 29
name <- namedb[i]
if (ndoc(dfmat_list[[name]]) > 0 && any(row_sums(dfmat_list[[name]]) > 0)) {
lda_list[[name]] <- LDA(dfmat_list[[name]], 10, control = list(alpha = 5), seed = SEED)
}
}
library(topicmodels)
lda_list <- list()
SEED = set.seed(1500)
for (i in 1:29) {  # Change to 29
name <- namedb[i]
if (ndoc(dfmat_list[[name]]) > 0 && any(rowSums(dfmat_list[[name]]) > 0)) {
lda_list[[name]] <- LDA(dfmat_list[[name]], 10, control = list(alpha = 5), seed = SEED)
}
}
library(topicmodels)
lda_list <- list()
SEED = set.seed(1500)
for (i in 1:29) {  # Change to 29
name <- namedb[i]
# Check if dfmat is not empty and contains at least one non-zero entry
if (ndoc(dfmat_list[[name]]) > 0 && any(apply(dfmat_list[[name]], 1, any))) {
lda_list[[name]] <- LDA(dfmat_list[[name]], 10, control = list(alpha = 5), seed = SEED)
}
}
library(topicmodels)
lda_list <- list()
SEED = set.seed(1500)
#this takes like 3 minutes
for (i in 1:29){
name = namedb[i]
lda_list[[name]] = LDA(dfmat_list[[name]], 10, control = list(alpha=5),seed=SEED)
}
View(lda_list)
knitr::opts_chunk$set(echo = TRUE)
# Using manifestoR package for dataset
library(manifestoR)
# Setting API key
mp_setapikey("manifesto_apikey.txt")
# Checking availability of United Kingdom data set for good practice
available_docs <- mp_availability(countryname == "United Kingdom")
available_docs
install.packages("prereg")
tinytex::install_tinytex()
install.packages("jsonlite")
install.packages("ggplot2")  # or any other visualization package you prefer
library(jsonlite)
json_data <- fromJSON("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/data/raw/fortran_test/fortran-lang-repos-postman.json")
View(json_data)
# This step heavily depends on the structure of your JSON file.
df <- as.data.frame(json_data)
View(df)
# data processing
library(tidyverse)
df %>%
select(id, name, full_name, html_url, description)
View(df)
df %>%
select(id, name, full_name, html_url, description)
selected_df <- df %>%
select(id, name, full_name, html_url, description)
# View the resulting data frame
print(selected_df)
View(selected_df)
# presenting the DF
install.packages("gridExtra")
install.packages("ggplot2")
library(gridExtra)
library(ggplot2)
table_plot <- tableGrob(selected_df)
png("selected_df.png", width = 800, height = 600)  # Adjust the size as needed
grid.draw(table_plot)
install.packages("ggplot2")
View(table_plot)
# By default, the code chunks are hidden for brevity. Set the echo argument to TRUE for blocks you want to share the code in the output for.
knitr::opts_chunk$set(echo = F)
knitr::include_graphics("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/pap/figures/Fortran FPM Pushes and Commits Over Time.png")
knitr::include_graphics("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/pap/figures/Fortran FPM Pushes and Commits Over Time.png")
knitr::include_graphics("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/pap/figures/Fortran FPM Pushes and Commits Over Time.png")
View(selected_df)
fortran-lang-repos-postman <- head(selected_df)
fortran_lang_repos_postman <- head(selected_df)
View(fortran_lang_repos_postman)
install.packages("jsonlite")
install.packages("ggplot2")  # or any other visualization package you prefer
library(jsonlite)
json_data <- fromJSON("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/data/raw/fortran_test/fortran-lang-repos-postman.json")
# This step heavily depends on the structure of your JSON file.
df <- as.data.frame(json_data)
# data processing
library(tidyverse)
selected_df <- df %>%
select(id, name, full_name, html_url, description)
fortran_lang_repos_postman <- head(selected_df)
knitr::kable(fortran_lang_repos_postman)
# Load packages and data to be clear from the start
library(jsonlite)
library(tidyverse)
json_data <- fromJSON("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/data/raw/fortran_test/fortran-lang-repos-postman.json")
df <- as.data.frame(json_data)
selected_df <- df %>%
select(id, name, full_name, html_url, description)
fortran_lang_repos_postman <- head(selected_df)
knitr::kable(fortran_lang_repos_postman)
# Load packages and data to be clear from the start
library(jsonlite)
library(tidyverse)
json_data <- fromJSON("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/data/raw/fortran_test/fortran-lang-repos-postman.json")
df <- as.data.frame(json_data)
selected_df <- df %>%
select(id, name, full_name, html_url, description)
fortran_lang_repos_postman <- head(selected_df)
# Load packages and data to be clear from the start
library(jsonlite)
library(tidyverse)
json_data <- fromJSON("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/data/raw/fortran_test/fortran-lang-repos-postman.json")
df <- as.data.frame(json_data)
selected_df <- df %>%
select(id, name, full_name, html_url, description)
fortran_lang_repos_postman <- head(selected_df)
knitr::kable(fortran_lang_repos_postman)
# Load packages and data to be clear from the start
library(jsonlite)
library(tidyverse)
json_data <- fromJSON("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/data/raw/fortran_test/fortran-lang-repos-postman.json")
df <- as.data.frame(json_data)
selected_df <- df %>%
select(id, full_name, html_url, description)
fortran_lang_repos_postman <- head(selected_df)
knitr::kable(fortran_lang_repos_postman)
fortran_lang_repos_postman <- head(selected_df)
knitr::kable(fortran_lang_repos_postman)
# By default, the code chunks are hidden for brevity. Set the echo argument to TRUE for blocks you want to share the code in the output for.
knitr::opts_chunk$set(echo = F)
library(readxl)
dataset_1 <- read_excel("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/data/raw/investment dataset.xlsx")
head(dataset_1)
library(readxl)
library(knitr)
# Load the dataset
dataset_1 <- read_excel("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/data/raw/investment dataset.xlsx")
# Display the first few rows with a more formatted table
kable(head(dataset_1), caption = "Head of Dataset 1")
fortran_lang_repos_postman <- head(selected_df)
# Load packages and data to be clear from the start
library(jsonlite)
library(tidyverse)
json_data <- fromJSON("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/data/raw/fortran_test/fortran-lang-repos-postman.json")
df <- as.data.frame(json_data)
selected_df <- df %>%
select(id, full_name, html_url, description)
View(selected_df)
View(df)
fortran_lang_repos_postman <- head(selected_df)
knitr::kable(fortran_lang_repos_postman)
kable(head(selected_df), caption = "Example of Repo Data From GitHub API")
# Load packages and data to be clear from the start
library(jsonlite)
library(tidyverse)
library(readxl)
library(knitr)
json_data <- fromJSON("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/data/raw/fortran_test/fortran-lang-repos-postman.json")
df <- as.data.frame(json_data)
selected_df <- df %>%
select(id, full_name, html_url, description)
dataset_1 <- read_excel("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/data/raw/investment dataset.xlsx")
kable(head(dataset_1), caption = "Head of Dataset 1")
kable(head(selected_df), caption = "Example of Repo Data From GitHub API")
dataset_2_fortran <- read_excel("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/data/raw/fortran_test/fortran_fpm_pushes_commits_raw.xlsx")
# Display the first few rows with a more formatted table
kable(head(dataset_2_fortran), caption = "Example of Repo Activity Data From GitHub API")
dataset_2_fortran <- read_excel("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/data/raw/fortran_test/fortran_fpm_pushes_commits_raw.xlsx")
# Display the first few rows with a more formatted table
kable(head(dataset_2_fortran), caption = "Example of Repo Activity Data From GitHub API")
dataset_2_fortran <- read_excel("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/data/raw/fortran_test/fortran_fpm_pushes_commits_raw.xlsx")
# Display the first few rows with a more formatted table
kable(head(dataset_2_fortran), caption = "Example of Repo Activity Data From GitHub API")
dataset_2_fortran <- read_excel("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/data/raw/fortran_test/fortran_fpm_pushes_commits_raw.xlsx")
# Display the first few rows with a more formatted table
kable(head(dataset_2_fortran), caption = "Example of Repo Activity Data From GitHub API")
kable(head(selected_df), caption = "Example of Organisation Data From GitHub API - Repositories")
dataset_2_fortran <- read_excel("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/data/raw/fortran_test/fortran_fpm_pushes_commits_raw.xlsx")
# Display the first few rows with a more formatted table
kable(head(dataset_2_fortran), caption = "Example of Fortran FPM Repo Activity Data From GitHub API")
knitr::include_graphics("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/pap/figures/Fortran FPM Pushes and Commits Over Time.png")
knitr::include_graphics("Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/pap/figures/data_schema.png")
knitr::include_graphics("Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/pap/figures/data_schema.png")
knitr::include_graphics("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/pap/figures/data_schema.png")
knitr::include_graphics("/Users/paulsharratt/Documents/Hertie/Semester 3/06 - Master's Thesis/thesis_stf/pap/figures/data_schema.png")
load("~/Documents/Hertie/Semester 4/03 - Master's Thesis/thesis_stf/data/workplaces/20240331.RData")
View(repo_commits_alls)
load("~/Documents/Hertie/Semester 4/03 - Master's Thesis/thesis_stf/data/workplaces/20240331.RData")
conn <- dbConnect(RPostgreSQL::PostgreSQL(), dbname = "augur", host = "data.chaoss.io", port = 5432, user = "pauluk", password = "TTxpk98T6?bK")
library(RPostgreSQL)
conn <- dbConnect(RPostgreSQL::PostgreSQL(), dbname = "augur", host = "data.chaoss.io", port = 5432, user = "pauluk", password = "TTxpk98T6?bK")
# Setting up connection parameters based on provided configuration
host <- "data.chaoss.io"
port <- 5432
dbname <- "augur"
user <- "pauluk"
password <- "TTxpk98T6?bK"
sslmode <- 'require' # Assuming SSL is needed based on the previous error
# Attempting to connect to the PostgreSQL database
conn <- dbConnect(RPostgreSQL::PostgreSQL(),
host = host,
port = port,
dbname = dbname,
user = user,
password = password,
sslmode = sslmode)
# Setting up connection parameters based on provided configuration
host <- "data.chaoss.io"
port <- 5432
dbname <- "augur"
user <- "pauluk"
password <- "TTxpk98T6?bK"
# Attempting to connect to the PostgreSQL database
conn <- dbConnect(RPostgreSQL::PostgreSQL(),
host = host,
port = port,
dbname = dbname,
user = user,
password = password)
dbListTables(conn)
library(jsonlite)
# Set working directory and base path
base_path <- "/Users/paulsharratt/Documents/Hertie/Semester 4/03 - Master's Thesis/thesis_stf/"
setwd(base_path)
# Pulling config file
config_path <- "config.json"
# Read the config file
config <- fromJSON(config_path)
View(config)
View(config)
# Connect to the database using the configuration list
conn <- dbConnect(RPostgreSQL::PostgreSQL(),
dbname = config$database,
host = config$host,
port = config$port,
user = config$user,
password = config$password,
sslmode = config$sslmode)
# Connect to the database using the configuration list
conn <- dbConnect(RPostgreSQL::PostgreSQL(),
dbname = config$database,
host = config$host,
port = config$port,
user = config$user,
password = config$password)
# Data import
treatment_group <- read_excel(paste0(base_path, "data/raw/investment/target_group.xlsx"))
# Data import
treatment_group <- read_excel(paste0(base_path, "data/raw/investment/target_group.xlsx"))
library(readxl)
treatment_group <- read_excel(paste0(base_path, "data/raw/investment/target_group.xlsx"))
View(treatment_group)
load("~/Documents/Hertie/Semester 4/03 - Master's Thesis/thesis_stf/data/workplaces/20240331.RData")
View(repo_commits_alls)
View(repo_group_check)
View(repo_group_data)
View(repo_group_filtered)
# Import augur repo groups all data
repo_groups_all <- read_csv("data/raw/augur/repo_groups_all.csv")
library(readr)
# Import augur repo groups all data
repo_groups_all <- read_csv("data/raw/augur/repo_groups_all.csv")
# View the first few rows of the dataframe
head(repo_groups_all)
View(repo_groups_all)
# Load the repo_group.csv file
repo_groups <- read_csv("data/raw/augur/repo_group.csv")
# View the structure and first few rows of the dataframe
str(repo_group)
repo_groups <- read_csv("data/raw/augur/repo_group.csv")
str(repo_group)
repo_group <- read_csv("data/raw/augur/repo_group.csv")
str(repo_group)
head(repo_group)
# Load dataset
commits_data <- read_csv("/data/total_commits_org_desc.csv") # Adjust path as necessary
# Load dataset
commits_data <- read_csv("data/raw/augur/total_commits_org_desc.csv") # Adjust path as necessary
# Basic Descriptive Statistics
summary_stats <- commits_data %>%
summarise(
Mean = mean(total_commits, na.rm = TRUE),
Median = median(total_commits, na.rm = TRUE),
SD = sd(total_commits, na.rm = TRUE),
Min = min(total_commits, na.rm = TRUE),
Max = max(total_commits, na.rm = TRUE)
)
library(tidyverse)
library(readr)
library(dplyr)
library(ggplot2)
# Load dataset
commits_data <- read_csv("data/raw/augur/total_commits_org_desc.csv") # Adjust path as necessary
# Basic Descriptive Statistics
summary_stats <- commits_data %>%
summarise(
Mean = mean(total_commits, na.rm = TRUE),
Median = median(total_commits, na.rm = TRUE),
SD = sd(total_commits, na.rm = TRUE),
Min = min(total_commits, na.rm = TRUE),
Max = max(total_commits, na.rm = TRUE)
)
# Print summary statistics to console
print(summary_stats)
# Histogram of Total Commits
hist_plot <- ggplot(commits_data, aes(x = total_commits)) +
geom_histogram(binwidth = 10, fill = "skyblue", color = "black") +
labs(title = "Distribution of Total Commits per Organization", x = "Total Commits", y = "Frequency")
# Display plot
print(hist_plot)
View(commits_data)
# Creating a bar plot
bar_plot <- ggplot(commits_data, aes(x = reorder(organization_name, total_commits), y = total_commits)) +
geom_bar(stat = "identity", fill = "steelblue") +
theme_minimal() +
labs(title = "Total Commits per Organization", x = "Organization", y = "Total Commits") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels for better readability
# Display the plot
print(bar_plot)
View(commits_data)
# Creating a bar plot
bar_plot <- ggplot(commits_data, aes(x = reorder(org_name, total_commits), y = total_commits)) +
geom_bar(stat = "identity", fill = "steelblue") +
theme_minimal() +
labs(title = "Total Commits per Organization", x = "Organization", y = "Total Commits") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels for better readability
# Display the plot
print(bar_plot)
# Define the file path for the output graph
output_file_path <- "/output/graphs/histogram_of_total_commits.png"
# Define the file path for the output graph
output_file_path <- "/output/graphs/histogram_of_total_commits.png"
# Save the histogram plot
ggsave(output_file_path, plot = bar_plot, width = 10, height = 8, dpi = 300)
# Display the plot
print(bar_plot)
# Define the file path for the output graph
output_file_path <- "output/graphs/histogram_of_total_commits.png"
# Save the histogram plot
ggsave(output_file_path, plot = bar_plot, width = 10, height = 8, dpi = 300)
# Print summary statistics to console
print(summary_stats)
# Basic Descriptive Statistics
summary_stats <- commits_data %>%
summarise(
Mean = mean(total_commits, na.rm = TRUE),
Median = median(total_commits, na.rm = TRUE),
SD = sd(total_commits, na.rm = TRUE),
Min = min(total_commits, na.rm = TRUE),
Max = max(total_commits, na.rm = TRUE)
)
# Print summary statistics to console
print(summary_stats)
save.image("~/Documents/Hertie/Semester 4/03 - Master's Thesis/thesis_stf/data/workplaces/20240405.RData")
